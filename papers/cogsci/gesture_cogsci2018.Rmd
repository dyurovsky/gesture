---
title: "Children gesture when speech is slow to come"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
 \author{Daniel Yurovksy, Madeline Meyers, Nicole Burke, Amanda Woodward, 
         \and Susan Goldin-Meadow \\
         \texttt{\{yurovsky, mcmeyers, nicoleburke, woodward, sgm\}@uchicago.edu} \\
        Department of Psychology \\ University of Chicago}


abstract: 
    "The abstract should be one paragraph, indented 1/8 inch on both sides,
in 9 point font with single spacing. The heading Abstract should
be 10 point, bold, centered, with one line space below it. This
one-paragraph abstract section is required only for standard spoken
papers and standard posters (i.e., those presentations that will be
represented by six page papers in the Proceedings)."
    
keywords:
    "Add your choice of indexing terms or keywords; kindly use a semi-colon; between each term."
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", 
                      fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(xtable)
#options(xtable.floating= FALSE)
library(feather)
library(tidyverse)

theme_set(theme_classic(base_size = 10))
```

# Introduction

Young children are inundated with language, hearing on the order of 30 million words by the time they are four years old [@hart1995]. From the statisitcal relationships within and among these words, children must discover the latent structures that allow them to become fluent speakers of their native language. Some of these words will be overheard, addressed by one parent to another or a sibling to a friend. However, some will be directed to the child, and these words maybe be particularly supportive of learning [@weisleder2013]. Child-directed speech is not merely a corpus of well-formed language; It is contingent on the child's own attention, interests, and prior knowledge, and thus can be directed *by the child themself*.

One way for children to direct their own input is to ask questions, a tool they employ with near-frustrating frequency and regularity. In her analysis of 5 children from the Brown and Kuczaj corpora in CHILDES, @chouinard2007 reports children asking over 100 questions per hour they interaction with adults over the 2-5 year range. However, long before they can explicitly direct their input with wh-questions, children can direct their input simply by referring to objects in their environment. Having observed a referential event, parents will often follow-in with expansions and additional information about the child's target of interest [@clark2014]

Even before they can produce, or even maybe know, the words for many objects in the world around them, infants engage their social partners in reciprocal interactions around objects they find interesting [@bruner1983]. Even before they can walk, children will engage in object-focused bids for an adult partner's attention, either pointing to a salient object of interest or carrying it over to share in joint attention [@tomasello2007,@karasik2011]. These bids can produce many of the same kinds of linguistic responses from parents as do spoken referential acts.

The goal of this work is to begin building a bridge between these two different ways in which children can communicate with conversational partners; to take a step in the direction of a generative model of children's referential productions. The primary target of interest will be predicting--for a given referential event--whether children are likely to use language, or are instead more likely to point or use another deictic gesture. 

# A race model for communcation

We conceptualize the referential process as being composed of two stages: First a decision about what to refer to, and then a subsequent process in which the communicative act is formed. In the following analyses, we leave the first process unspecified--we will not attempt to model how children choose their target of reference. However, once a referent is chosen, we can think of the communicative act as the output of a race between two independent accumluators: One for speech, and one for gesture. At every timestimep, each of the two accumulators accumulator increases with a probability proportional to its own drift rate, and the accumulator that reaches threshold first wins (see e.g. @brown2008). 



Three predictions of a race model for communication:
three predictions:
		1. frequency predicts gesture vs. speech
		2. over development, children learn more language and so speech should win the race more often because words should be easier to retrieve
		3. recent boosts in a word should make it easier to retrieve: in the same discourse burst, more likely to use speech for low frequency words
		
We test all three of these predictions in a large longitidunal corpus of parent-child interaction.

# Method

```{r load_corpus}
coded_responses <- read_feather("../../feathers/coded_responses.feather")
demos <- read_feather("../../feathers/demos.feather") %>%
  filter(id != 47, id != 110)
referents <- read_feather("../../feathers/referents.feather")

subjs <- coded_responses %>%
  distinct(subj) %>%
  pull()

ages <- coded_responses %>%
  distinct(age) %>%
  pull()

income<-c("Less than $15,000", "$15,000-$34,999", "$34,999-$49,999", "$50,000-$74,999", "$75,000-$99,999", "$100,000 or more" )

```

Get a corpus, code the corpus,

# Corpus

The data analyzed here are transcriptions of recordings parent-child interactions in the homes of `r length(subjs)` children from the Chicagoland area. Each recording was ~90min long, and participants were given no instructions about how to interact--the goal was to observe the naturalistic ecology of language learning. Each child was recorded `r length(ages)` times at 4-month intervals starting at `r min(ages)`-mo. and ending at `r max(ages)`-mo. 

These children's data was drawn from the larger Language Development Project dataset pseudo-randomly to preserve the socio-economic, racial, and gender diversity of the children as a representation of the broader Chicago community. Of the `r length(subjs)` children, `r demos %>% summarise(female = sum(sex == "F")) %>% pull()` were girls, `r demos %>% summarise(black = sum(race == "BL")) %>% pull()` were Black and `r demos %>% summarise(mixed = sum(race == "2+")) %>% pull()` were Mixed-Race. Socioeconomic status was measured by family income, with four families earning less than `r income[3]` and two families earning `r income[6]`. The average family income for the subjects included in this study was `r income[4]`. 

## Data Processing

The original Language Development Project transcripts consist of utterance-by-utterance transcriptions of the 90 minute recordings in CHAT format [@macwhinney2000], as well as a transcription of all communicative gestures produced by children and their conversational partners, including conventional gestures (e.g. waving 'bye"), representational gestures (e.g. tracing the shape of a square), and deictic gestures (e.g. pointing to a ball).

For each of these communicative acts, we coded all concrete noun referents indicated in either the spoken or gestural modality (see Table 1). As it is difficult both to gesture about, and to code, gestures for abstract entities like “weekend,” we focused only on nouns that could be referred to in either gesture or speech. Spoken referents were coded only if a noun label was used (e.g. no pronouns were included), and only deictic gestures were counted as referential to minimize ambiguity in coding. Synonyms, nicknames, and proper nouns were all coded according to a manual that can be found at [CODING MANUAL???].


```{r coding_table, results="asis", tab.env = "table"}

coding_table <- read_csv("figs/coding_table.csv") %>%
  remove_rownames() %>%
  xtable(caption = "An example of the output of data processing") 


print(coding_table, type = "latex", comment = F, table.placement = "tb",
      include.rownames = FALSE)

```

## Validation

### Referent Presentness

Although we coded for concrete referents that theoretically could be produced either in speech or in gesture, we found that these referents were not always physically present in the environment. Therefore, not every referent had a nonzero probability of being gestured to, as parents and children occasionally talk about events that have happened in the past or future, items that are in different locations, or characters who are not present. Therefore, we coded for whether the referent was physically present in the environment, and included only those referents that were present in the following analysis. On average, 87% of referents were present during the discourse. There was a significant effect of age (p<0.0098), where 91% of referents with the youngest children (14 months) were present, and 84% of referents with the oldest children (34 months) were present. 

### Reliability

In order to assess the reliability of concrete noun coding, agreement was calculated for two independent coders. The Cohen's Kappa statistic for a comparison of 27% of the data was 0.81. Issues and discrepancies in coding decisions were dicussed and resolved during the formation of the coding manual.  

Reliability for referent presentness was caluclated through a comparison of predicted and manual codes. Predicted presentness calculations were created using transcripts according to the guidelines found in [CODING MANUAL??]. Referents were predicted to be present in the environment if they were gestured to recently, if they were labeled by a subject, or if they were in a picture book. Maual presentness calculations were made for 5% of the data by watching the video recording of the 90-minute session and marking whether the object being disucssed was in view in the environment. The percent reliability for these sessions was 98%, with a Cohen's Kappa statistic of 0.979. 

# Results

The key predictions of our race model of reference all connect the ease of recall of a referent's spoken label. Although ease of recall is likely related to a number of factors (e.g. phonotactic probability, neighborhood density, etc), we focus here on one easily quantifiable and well-attested predictor: input frequency [@wingfield1968]. 

## Estimating Frequency

To estimate the input frequency of each referent in the corpus, we summed its frequency of use across all children and parents and across both the speech and gestural modalities. This estimator is of course imperfect-- It assumes, for instance, that every child receives the same input, and that input frequency is stationary across development. Nonetheless, because of the difficulty of estimating these frequencies well especially from a corpus of this size, we felt that a more complex estimator would introduce more error than it was worth.

```{r freq_fig,  fig.width=3.5, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "One column image"}
label_refs <- referents %>%
  filter(referent %in% c("mom", "baby", "train", "dinosaur", "zucchini",
                          "cauliflower", "windchime"))

ggplot(referents, aes(x = rank, y = freq)) + 
  geom_point(size = .1) + 
  scale_x_log10(name = "Rank Frequency", breaks = c(1, 10, 100, 1000)) + 
  scale_y_log10(name = "Frequency", breaks = c(1, 10, 100, 1000)) + 
  geom_label(data = label_refs, aes(label = referent), color = "#e41a1c",
             size = 2)

```

Figure 1 shows the frequency distribution of the `r nrow(referents)` individual referents in this corpus across all recordings. As with many other frequency distributions in language, referential frequencies were approximately Zipfian, appearing approximately linear on a log-log scale [@piantadosi2014]. These frequency estimates were used to test the first key prediction of the race model of communcation: Labels for referents that are easier to retrieve from memory are more likely to be produced in speech.

## Testing the Race Model


Figure 1 shows the distribution of 

primary independent variable in the predictions made by the race model of reference is 


All artwork must be very dark for purposes of reproduction and should
not be hand drawn. Number figures sequentially, placing the figure
number and caption, in 10 point, after the figure with one line space
above the caption and one line space below it. If necessary, leave extra white space at
the bottom of the page to avoid splitting the figure and figure
caption. You may float figures to the top or bottom of a column, or
set wide figures across both columns.

## Tables

Number tables consecutively; place the table number and title (in
10 point) above the table with one line space above the caption and
one line space below it, as in Table 1. You may float
tables to the top or bottom of a column, set wide tables across both
columns.

You can use the xtable function in the xtable package.

```{r xtable, results="asis"}
n <- 100
x <- rnorm(n)
y <- 2*x + rnorm(n)
out <- lm(y ~ x)

tab1 <- xtable::xtable(summary(out)$coef, digits=c(0, 2, 2, 1, 2), 
                      caption = "This table prints across one column.")

print(tab1, type="latex", comment = F, table.placement = "H")
```

## Frequency of use


```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}
img <- png::readPNG("figs/walrus.png")
grid::grid.raster(img)
```

## One-column images

Single column is the default option, but if you want set it explicitly, set `fig.env` to `figure`. Notice that the `num.cols` option for the caption width is set to `1`.

```{r image, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "One column image."}
img <- png::readPNG("figs/lab_logo_stanford.png")
grid::grid.raster(img)
```


## R Plots

You can use R chunks directly to plot graphs. And you can use latex floats in the
fig.pos chunk option to have more control over the location of your plot on the page. For more information on latex placement specifiers see **[here](https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions)**

```{r plot, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2, fig.height=2, fig.cap = "R plot" }
x <- 0:100
y <- 2 * (x + rnorm(length(x), sd = 3) + 3)

ggplot2::ggplot(data = data.frame(x, y), 
       aes(x = x, y = y)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```



# Acknowledgements

This research was funded by a James S. McDonnell Foundation Scholar Award to DY and National Institutes of Health P01HD40605 to SGM.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
