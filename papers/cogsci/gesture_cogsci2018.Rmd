---
title: "Children gesture when speech is slow to come"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
 \author{Daniel Yurovksy, Madeline Meyers, Nicole Burke,
         \and Susan Goldin-Meadow \\
         \texttt{\{yurovsky, mcmeyers, nicoleburke, sgm\}@uchicago.edu} \\
        Department of Psychology \\ University of Chicago}


abstract: 
    "Human conversation is marked by alternation--partners taking turns speaking and listening. Consequently, language production happens under time pressure; speakers who cannot get their message out quickly enough lose their turn. When adults have struggle to retrieve the words they want to say, they can choose alternatives. But children just beginning to learn language may solve this problem with gesture. If young children\\'s production systems reflect a sensitivity to communicative pressure, they should use deictic gesture to refer when they cannot retrieve a lexical label quickly enough. We confirm this prediction in a longitudinal corpus of naturalistic parent-child interactions, showing that the frequency and recency of a word in children\\'s input predict the probability that they will refer to its referent with gesture, *even for words they know*."
keywords:
    "communication; language acquisition; gesture"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = T, fig.pos = "tb", 
                      fig.path='figs/', echo = F, warning = F, cache = F, 
                      message = F, sanitize = T)
```

```{r, libraries}
library(tidyverse)
library(png)
library(grid)
library(xtable)
library(feather)
library(tidyverse)
library(irr)
library(tidyboot)
library(directlabels)
library(lme4)
library(broom)

theme_set(theme_classic(base_size = 10))
```

# Introduction

Children learn a striking amount of language in their first few years of life--thousands of sounds, words, grammatical categories, and the relationships among them that allow their combination into meaningful utterances. Children also come to understand what all of this language *is for*: communicating with other people [@clark2009; @zipf1949]. There is good reason to think that these two problems are deeply intertwined. The language children hear is rarely a running commentary on the world around them--when a child's parents return home from work, they are much more likely to say "whatcha been doing all day?" than "I am opening the door" [@gleitman1990]. Knowing that the parent's goal is not to talk about the door may help significantly in discovering the meaning of their words.

Adults routinely make use of inferences about a speaker's communicative goal in language processing. These pragmatic inferences, for instance, are why hearing a speaker say that they ate "some of the cookies," causes us to think that some cookies still remain on the plate [@grice1969]. Children's ability to perform complex inferences of this kind appears relatively late in language development [@noveck2001]. However, a growing body of empirical evidence shows that a basic understanding of the communicative purpose of language is already present in the first year of life. For instance, children appear to understand that speakers communicate information to other adults, even if they themselves do not understand the words being said [@vouloumanos2012]. Do children also show this understanding of communicative goals in their production of language?

A core feature of communicative interactions is turn taking: Participants each contribute to the discourse, but only one at a time [@sacks1974]. Turn taking is not only appears consistently among both modern and indigenous cultures, the length of time between turns is highly stereotyped--predicted by the same factors across cultures [@stivers2009]. Evidence from both early observational studies and more recent experiments suggests that tracking of turn boundaries emerges early in infancy--perhaps in the course of scripted interactions like patty cake [@bruner1983; @casillas2017].

The regularity of turns makes communication inherently time constrained: If you stop talking for too long, you lose your turn. Adults are sensitive to this time pressure, for instance producing filled pauses like "um" when they are having difficulty retrieving the words they want to produce in order to signal their desire to hold onto their turn [@clark2002]. If retrieval is still unsuccessful, linguistically-proficient adults can opt for an alternative word or even a description that gives their interlocutor enough information to help retrieve the word for them [@clark1989]. Children still learning their native language, for whom such strategies are unavailable, might resort to an alternative mode of communication: pointing. 

Children produce deictic gestures early in infancy, and appear to understand that these gestures both direct attention and communicate intentions by the time they are 12-months-old [@liszkowski2007; @tomasello2007]. Around the same time, infants begin producing their first spoken words [@bloom2000]. Over the next few years, infants will produce many more words, and need to rely less on deictic gesture to communicate. However, while children master some words early, others which are less frequent may remain difficult to retrieve and produce. If children, like adults, are sensitive to the time pressures of communication, then then they may use gesture even for *known* words if these words are slow to come.

## Communication as a race between modalities

When children wish to share their interest in an object with a caregiver, they have two modalities available to them. One possibility is to use spoken language, producing the canonical label for it (e.g. "ball"). Alternatively, they can use a deictic gesture, e.g. a point, to draw the caregiver's attention to it. When should children use each of these modalities? 

If the child does not know that the object is called "ball," they have no choice but to point. However, if they *do* know its label, time pressure on communication produces a race between modalities. If the child can recall the word quickly, they should prefer to use language--speech is less effortful than pointing [@zipf1949]. However, if recalling and producing the word is happening too slowly, the child risks losing their conversational turn and should instead point. 

```{r lba-mod, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 2, num.cols.cap=1, fig.cap = "Reference as as a race between modalities. The drift rate of pointing should be independent of referent, but speech should vary with properties of words, e.g. frequency.", cache = T}
img <- png::readPNG("figs/lba_mod_simple.png")
grid::grid.raster(img)
```

This kind of race model can be formalized nicely as two competing accumulators [see e.g. @brown2008]. Each modality accumulates activation at its own independent rate, and whichever is the first to reach threshold wins the race and is used to make the intended reference (Figure \ref{fig:lba-mod}). Although the difficulty of pointing may vary due to issues of proximity of the speakers to each-other, the location of the target referent, etc., the difficulty of pointing should in general be independent of the referent. On the other hand, the difficulty of recalling and producing a word varies from word to word. In adults, this difficulty is influenced by many features of the word, including the phonology and orthography of both the word and its neighbors in the lexicon [see e.g. @vitevitch2008]. Here we focus on just one--contributor: Input frequency [@wingfield1968]. The more frequently we hear a word, the easier it is for us to retrieve and produce it. Children's *language processing* shows similar effects of frequency--children's speed and accuracy of known words increases as they become more frequent [@swingley1999]. If their *language production* is similarly affected by frequency, than the rate of the speech accumulator should increase as frequency increases, resulting in it winning the race for reference more often.

This framework makes detailed predictions about the relationship between modality and production time as features of the target referent change. We test three such predictions in children's spontaneous references from 14- to 34-months:

1. As the frequency of a referent in children's input increases, children should be more likely to use speech rather than gesture to communicate about it.

2. As children develop and learn more language, words should be known better and thus be easier to retrieve. Thus, speech should win the race more often in older children--especially for low frequency words.

3. Recent use of a word should make it easier to retrieve. Consequently, children should be more likely to use speech to refer to low-frequency referents if they are already in the current discourse. 

# Method

```{r load_corpus, cache = T}
referents <- read_feather("../../feathers/referents.feather") %>%
  mutate(freq_cut = 5- as.numeric(cut(log(freq), 4)))

coded_responses <- read_feather("../../feathers/coded_responses.feather") %>%
  select(-freq_cut, -rank, - freq) %>%
  left_join(referents)

demos <- read_feather("../../feathers/demos.feather") %>%
  filter(!id %in% c(47, 110)) %>%
  mutate(income_factor = factor(round(income), levels = c(1, 2, 3, 4, 5, 6), 
                       labels=c("Less than $15,000", "$15,000 to $34,999",
                                "$35,000 to $49,999", "$50,000 to $74,999",
                                "$75,000 to $99,999", 
                                "greater than $100,000")))
         
subjs <- coded_responses %>%
  distinct(subj) %>%
  pull()

ages <- coded_responses %>%
  distinct(age) %>%
  pull()

missing <- coded_responses %>%
  distinct(subj, age) %>%
  mutate(present = TRUE) %>%
  complete(subj, age, fill = list(present =  FALSE)) %>%
  filter(present == F) %>%
  pull(age)
# 
# income_labs<-c("Less than $15,000", "$15,000 to $34,999", "$35,000 to $49,999", "$50,000 to $74,999", "$75,000 to $99,999", "Greater than $100,000")
```

The data analyzed here are transcriptions of recordings parent-child interactions in the homes of `r length(subjs)` children from the Chicagoland area. Each recording was $\sim\mkern-4mu$ 90min long, and participants were given no instructions about how to interact--the goal was to observe the natural ecology of language learning. Each child was recorded `r length(ages)` times at 4-month intervals starting at `r min(ages)`-mo. and ending at `r max(ages)`-mo. (except one child at `r missing`-mo.).

## Participants

These children's data were drawn from the larger Language Development Project dataset pseudo-randomly to preserve the socio-economic, racial, and gender diversity representative of the broader Chicago community [@goldin-meadow2014]. Of the `r length(subjs)` children, `r demos %>% summarise(female = sum(sex == "F"))` were girls, `r demos %>% summarise(black = sum(race == "BL"))` were Black and `r demos %>% summarise(mixed = sum(race == "2+"))` were Mixed-Race. Families spanned a broad range of incomes, with `r demos %>% filter(income == min(income)) %>% nrow()` families earning `r demos %>% filter(income == min(income)) %>% pull(income_factor) %>% first()` and `r demos %>% filter(income == max(income)) %>% nrow()` family earning `r demos %>% filter(income == max(income)) %>% pull(income_factor) %>% first()`. The median family income was `r demos %>% filter(income == median(income)) %>% pull(income_factor) %>% first()`. 

## Data Processing

The original Language Development Project transcripts consist of utterance-by-utterance transcriptions of the 90 minute recordings, as well as a transcription of all communicative gestures produced by children and their caregivers, including conventional gestures (e.g. waving "bye"), representational gestures (e.g. tracing the shape of a square), and deictic gestures (e.g. pointing to a ball).

```{r coding-table, results="asis", tab.env = "table", cache = T}
coding_table <- read_csv("figs/coding_table.csv") %>%
  remove_rownames() %>%
  select(-referent) %>%
  xtable(caption = "Referents coded in a few lines of one transcript.",
         align = "llp{2.5cm}lll",
         label = "tab:coding-table")

print(coding_table, type = "latex", comment = F, table.placement = "tb",
      include.rownames = FALSE,
      size="\\fontsize{8pt}{8pt}\\selectfont")
```


For each of these communicative acts, we coded all concrete noun referents produced in either the spoken or gestural modality (see Table \ref{tab:coding-table}). As it is difficult both to gesture about and to code gestures for abstract entities like “weekend,” we focused only on nouns that could be referred to in either gesture or speech. Spoken referents were coded only if a noun label was used (e.g. no pronouns were included), and only deictic gestures were counted as referential to minimize ambiguity in coding. Synonyms, nicknames, and proper nouns were all coded according to the manual available in the $\texttt{github}$ repository linked below.

## Reliability

In order to ensure the integrity of the coded data for further analyses, we first assessed inter-rater reliability, and then whether the spoken referents were  available in the scene and could have been referred to in gesture.

### Inter-Rater Reliability

```{r reliability, cache = T}
nicole_responses <- 
  read_feather("../../feathers/interrater_data_nicole.feather") %>%
  select(subj, age, time, referent, modality) %>%
  mutate(coder = "Nicole") %>%
  mutate(referent = if_else(is.na(referent), "NA", referent))

maddie_responses <- 
read_feather("../../feathers/interrater_data_maddie.feather") %>%
  select(subj, age, time, referent, modality) %>%
  mutate(coder = "Maddie") %>%
  mutate(referent = if_else(is.na(referent), "NA", referent))

irr_data <- full_join(nicole_responses, maddie_responses, 
                      by = c("time", "subj", "age", "modality")) %>%
  filter(!is.na(modality))

kappa <- irr_data %>%
  select(referent.x, referent.y) %>%
  kappa2()

```

To assess reliability of referent coding, 25% of the transcripts were double-coded. Reliability between coders was good (Cohen's $\kappa$ = `r round(kappa$value,2)`). Issues and discrepancies in coding decisions were discussed and resolved during the formation of the coding manual.  

### Presence of referents

```{r presentness_data, cache = T}
reliability_data<-read_feather("../../feathers/pres_reliability.feather")
 
child_reliability <- reliability_data %>%
   filter(person == "child") %>%
   select(ref_pres, ref_predicted) %>%
   kappa2()
 
all_reliability<-reliability_data %>%
   select(ref_pres, ref_predicted) %>%
   kappa2()

presentness <- coded_responses %>%
  mutate(ref_predicted = as.numeric(ref_predicted))

present_lm <- glmer(ref_predicted ~ scale(age) * person + (person|subj), 
       family = "binomial", 
       data = presentness)
 
 presentness_age<-presentness %>%
   filter(is.na(ref_predicted)==FALSE) %>%
   group_by(age) %>%
   summarise(mean=(sum(ref_predicted)/n()))
 
 presentness_person<-presentness %>%
   group_by(person) %>%
   summarise(mean=sum(ref_predicted)/n()) 
```

To ensure that each referent could have been referred to both speech and deictic gesture, we coded for concrete nouns. However, when watching a subset of the original videos, we found that not all of these were physically present in the environment. A referent that was not physically present could have been difficulty to gesture to--potentially biasing our analyses [although, c.f. @butcher1991]. After coding all referents from the transcripts, the primary coder judged whether each was likely to be present in the scene according to a list of criteria described in the coding manual linked below. 

Across the 59 transcripts, `r presentness %>% summarise(present = mean(ref_predicted)) %>% pull() %>% round(2) * 100`% of referents were judged to be present. A mixed effects model predicting presence from child's age and whether the speaker was a parent or child found no significant main effects, but did find a significant interaction between age and speaker ($p < .001$), with parents of older children more likely to talk about absent referents. Absent referents were included in estimates of input frequency, but excluded from analyses of production modality.

Reliability for judgments of referent presence was calculated by comparing 5% of the transcripts to observations of video data. Reliability was acceptable for child-produced referents ($\kappa$= `r round(child_reliability$value,2)`), as well as for all referents in the dataset ($\kappa$=`r round(all_reliability$value,2)`).

# Results

We set out to test three key predictions of the race model connecting the ease of retrieval and production of a referent's label to the probability that children refer to it in speech rather than gesture. Although ease of recall is likely related to a number of factors (e.g. phonotactic probability, neighborhood density, etc), we focus here on one easily quantified and well-attested predictor: input frequency [@wingfield1968]. 

## Estimating Frequency

To estimate the input frequency of each referent in the corpus, we summed its frequency of use across all children and parents and across both the speech and gestural modalities. This estimator is of course imperfect-- It assumes, for instance, that every child receives the same input, and that input frequency is stationary across development. Nonetheless, because of the difficulty of estimating these frequencies well, especially from a corpus of this size, we felt that a more complex estimator was likely to introduce statistical bias.

```{r freq-fig,  fig.width=3.5, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "Referents varied widely in their frequency of use, appearing approximately Zipfian. Referents frequent in the input--like baby--should be be more likely to emerge in speech than infrequent referents like cauliflower", cache = T}
label_refs <- referents %>%
  filter(referent %in% c("mom", "baby", "train", "nose", "dinosaur",
                          "cauliflower", "windchime"))

ggplot(referents, aes(x = rank, y = freq)) + 
  geom_point(size = .1) + 
  scale_x_log10(name = "Rank Frequency", breaks = c(1, 10, 100, 1000),
                limits = c(.95,1800)) + 
  scale_y_log10(name = "Frequency", breaks = c(1, 10, 100, 1000)) +
  geom_label(data = label_refs, aes(label = referent), color = "#e41a1c",
             size = 2) 

```

Figure \ref{fig:freq-fig} shows the frequency distribution of the `r nrow(referents)` individual referents in this corpus across all recordings. Like many other frequency distributions in language, referential frequencies were approximately Zipfian, appearing approximately linear on a log-log scale [@piantadosi2014]. These frequency estimates were used to test the predictions of the race model of communication.

## Predictions 1 and 2: The effects of frequency

If the modality that children use for referential communication is the result of a race between speech and gesture, factors that facilitate lexical retrieval and word production should make speech win the race more often. As more frequent words lead to faster retrieval in adults, we hypothesized that frequency should have the same effect for young children. Consequently, when children want to refer to things that are talked about more often, they should be more likely to use speech (Prediction 1). Further, since exposure to language increases over development, older children should be relatively more likely than younger children to use speech for referents that are heard equally often. (Prediction 2).

```{r tradeoff_estimate, cache = T}
model_data <-  coded_responses %>%
  filter(ref_predicted == "1", person == "child")

plotting_data <- model_data %>%
  group_by(person, age, subj, freq_cut, modality) %>%
  summarise(n = n()) %>%
  mutate(prob = n/sum(n)) %>%
  group_by(person, age, modality, freq_cut) %>%
  tidyboot_mean(prob, na.rm = T) %>%
  ungroup() %>% 
  filter(modality != "both") %>%
  mutate(age = paste0(age, " months")) %>%
  complete(age, modality, person, freq_cut, 
           fill = list(person = "child", mean = 0, ci_upper = 0, ci_lower = 0))
```


```{r tradeoff-plot, fig.env = "figure*", fig.width=5.5, fig.height=3.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Probability of referential events being expressed in speech (blue) vs. gesture (red) as a function of frequency and children's age. For ease of visualization, referents were divided into four quartiles (1-most frequent). Points show group averaed proportions, error bars show 95\\% confidence intervals computed by non-parametric bootrstrap", cache = T}
ggplot(plotting_data, aes(x = freq_cut, y = mean, color = modality,
                          label = modality)) +
  geom_line()+
  facet_wrap( ~ age) + 
  geom_pointrange(aes(ymax = ci_upper, ymin = ci_lower), 
                 position = position_dodge(.5)) + 
  scale_color_brewer(palette = "Set1") +
  geom_dl(method = list(dl.trans(x=x +.2), "last.qp", cex=.7)) +
  scale_x_continuous(limits = c(.5, 5.7),
                     breaks = seq(1, 4),
                     name = "Frequency Quartile") +
  ylab("Production Probability") + 
  theme(legend.position = "none")
```


Figure \ref{fig:tradeoff-plot} shows how the probability of speech and gesture changed with referents' frequency and over development. We performed all statistical analyses on continuous frequency data, but to facilitate visualization divided referents into four quartiles from most frequent (1) to least frequent (4). Children were relatively more likely to use speech for more frequent referents, and more likely to use speech over development. These data are consistent with both of the first two predictions of our race model for communication.

```{r tradeoff_model, cache = T}
tidy_table <- function(mermod) {
  tidy(mermod) %>%
    filter(group == "fixed") %>%
    select(-group) %>%
    mutate(p.value = if_else(p.value < .001, "<.001", 
                             as.character(round(p.value, 2)))) %>%
    mutate(estimate = sprintf("%.2f",round(estimate, digits = 2)),
           std.error = sprintf("%.2f",round(std.error, digits = 2)),
           estimate = paste0(estimate, " (", std.error, ")"),
           estimate = sub("0.", ".", estimate)) %>%
    rename(`estimate (SE)` = estimate) %>%
    select(-std.error) %>%
    rename(`Z-value` = statistic,
           `p-value` = p.value)

}


tradeoff_model <- glmer(cbind(modality != "gesture", modality== "gesture") ~ 
                          log(freq) * scale(age) + (scale(age)|subj) + (1|referent),
                        family = "binomial", data = model_data)
```

```{r model-table, results="asis", tab.env = "table", cache = T}
model_table <- tidy_table(tradeoff_model) %>%
  mutate(term = c("Intercept", "log frequency", "age",
                  "log frequency * age")) %>%
    xtable(caption = "Coefficient estimates for a mixed-effects logistic regression predicting probability of prodution in speech for a referential event. The model was specified as \\texttt{speech $\\sim$ log(freq) * scale(age) + (scale(age)|subj) + (1|referent)}",
           label = "tab:model-table")

print(model_table, type = "latex", comment = F, table.placement = "tb",
      include.rownames = FALSE)
```

```{r sub_model, cache = T, eval = F}
sub_data <- model_data %>%
  group_by(freq, subj, age, referent, modality) %>%
  summarise(n = n()) %>%
  spread(modality, n) %>%
  filter(!is.na(gesture) & (!is.na(speech) | !is.na(both))) %>%
  mutate(speech = max(speech + both, speech, both, na.rm = T)) %>%
  select(-both)

sub_model <- glmer(cbind(speech, gesture) ~ log(freq) * scale(age) +
                     (scale(age)|subj) + (1|referent), 
                   family = "binomial", 
                   control = glmerControl(optimizer = "bobyqa"),
                   data = sub_data)

tidy_table(sub_model)
````

To test these predictions statistically, we used as our dependent variable the modality of production for each individual referential event by every child at all six ages. This binary outcome--speech or gesture--was predicted with a mixed effects logistic regression with fixed effects of frequency, age, and their interaction, and a random slope of frequency for each child and random intercept for each referent. As the effect of frequency on memory and processing tends to be linear in log scale, frequency was log-transformed. In addition, age was scaled to improve model estimation. Both main effects were highly reliable, as was the interaction between them (Table \ref{tab:model-table}). Children were significantly more likely to use speech to refer to more frequent referents, more likely to use speech as they got older, and the effect of frequency decreased over development--presumably because the easiest to retrieve referents already win the race even for younger children. 

Because these analyses were performed on all references for all children, some referents were produced only one or a few times, and thus only in a single modality. When this modality was gesture, we cannot know whether children knew the spoken labels for these referents, and thus whether there was a race at all. To ensure that our results were not driven by words that children did not know, we subset the data down to only referents that children produced in *both* speech and gesture in a single session. All predictors remained significant in the same direction, and numerically similar except for age, which decreased (as the most well-known referents were never produced in gesture and thus excluded from analysis). Even by this more conservative analysis, both predictions of the race model were confirmed: Children are more likely to use speech for more frequent referents, and more likely to do so as they get older. Even for words that children can produce, the speed of lexical retrieval and production predict whether they will gesture instead.

## Prediction 3: Recent referents get a boost

If children's referential communications are produced by a system that is sensitive to the time-pressure on communication, speech should emerge more often as labels become easier to retrieve and produce. The previous analyses confirm this relationship for one predictor of ease of retrieval: Lexical frequency. 
However, these references do not occur in a vacuum: they are embedded in broader communicative discourses. A key feature of these discourses is that referential events come in bursts: If a something is referred to in one utterance, it is likely to be referred to again in the next utterance [@altmann2009].

These topical bursts likely occur for functional reasons--once something interesting has entered the discourse, there is no reason to drop it right away. But they also have an important consequence for production. Although low-frequency words are harder to retrieve the first time, subsequent retrievals in the same discourse become easier; these words get a recency boost [@pickering2008]. If the drift rate for speech is a function of ease of retrieval, then it should be affected by these bursts as well. Consequently, we predict that children should be relatively more likely to speech to refer to low-frequency referents within a discourse burst than if their reference is the first introduction of the low-frequency referent into the discourse.

In order to test this prediction, we needed to operationalize the boundaries between discourse bursts. When a referent appears for the first time in a transcript, it is easy to tag as new to the discourse. When it is immediately referred to again, it is also easy to determine that it is part of the same discourse burst. However, whenever the referent appears again after 5 minutes, it is less obvious whether this is a part of the previous discourse burst or the start of a new one. To resolve this issue, we defined a simple bag of referents model for discourse. 

In this model, the target of each referential event is modeled an independent draw from the set of all referents with probability proportional to its frequency [@altmann2009]. For independent draws from this Poisson sampling process, the recurrence time $(\tau)$ between two successive occurrences of the same referent follows an Exponential distribution: $\tau \sim \lambda e^{-\lambda \tau}$, where $\lambda$ is the proportion of all referential events for which this referent is the target. The expected recurrence time for a referent is thus the reciprocal of this proportion. For example, if DOG occurs 50 times in a discourse in which there are a total of 1000 referential events, it should on average occur every $\tau=20$ events.

The bag of referents model then serves as a null model: Discourse bursts are very low probability events, as they consist of a run of short recurrence times. We thus define the probability of an event being part of a previous discourse as the probability of drawing a recurrence time at least that short for it from the bag of words model. Figure \ref{fig:gleit-plot} shows a Gleitman plot of a segment of one parent-child interaction [@frank2013]. Each tile indicates the occurrence of a particular referent on a particular utterance, and thus read from left to right it describes the emerging conversation over successive utterances in time. The colors of the tiles show the probabilities assigned by the bag of referents model that these occurrences are new discourse bursts.

```{r burstiness, cache = T}
indiv_freqs <- coded_responses %>%
  group_by(subj, age, referent) %>%
  summarise(indiv_freq = n()) %>%
  mutate(total_refs = sum(indiv_freq))
  
lags <- coded_responses %>%
  mutate(time2 = as.numeric(time2)) %>%
  arrange(subj, age, time2) %>%
  group_by(subj, age, referent) %>%
  mutate(time2 = as.numeric(time2),
         diff = time2 - lag(time2)) %>%
  left_join(indiv_freqs) %>%
  group_by(subj, age) %>%
  mutate(freq_prob = indiv_freq / total_refs,
         predicted = total_refs / indiv_freq,
         new_discourse = pexp(diff, freq_prob, lower.tail = T),
         new_discourse = if_else(is.na(new_discourse), 1, new_discourse))
```

Because referents that have occurred recently should be easier to retrieve, the race model predicts that referents within a discourse burst should have faster drift rates and thus come out in speech more often than if they were retrieved to to begin a discourse burst. We test this prediction by adding the new discourse burst probability predictor to our previous mixed-effects model predicting the probability that a child's reference will use the speech modality \ref{tab:lag-table}. Both frequency and age remained highly significant predictors, as did their interaction. In addition, referents starting a new discourse burst were reliably less likely to be produced in speech, and this effect interacted with both frequency and age. Discourse novelty lead to gesture particularly for infrequent referents and for younger children. Thus, children are more likely to use speech to refer when words that they are generally slow to retrieve have temporarily gotten a boost.

```{r gleit-plot, fig.env = "figure", fig.align = "center", fig.height = 1.75, fig.width = 3.5, fig.cap ="A Gleitman plot of a slice of parent-child interaction. Tiles show which objects are referents of each utterance. Tile color shows predicted probability of being a new discourse topic under the bag of referents model", cache = T}

sub_lags <- lags %>%
  ungroup() %>% 
  slice(2480:2515) %>%
  mutate(referent = factor(referent, levels = rev(unique(referent))))

ggplot(sub_lags, aes(x = as.numeric(time), y = referent)) + 
  geom_tile(aes(fill = new_discourse), color = "white") + 
  scale_fill_gradient(low = "lightgray", high = "red",
                      guide = guide_colorbar(title = "P(new)",
                                             title.position = "left",
                                             barwidth = 1,
                                             barheight = 2.6),
                      limits = c(0, 1),
                      breaks = c(0, .5, 1),
                      labels = c("0", ".5", "1"))+
  scale_x_continuous(name = "Utterance number") +
  scale_y_discrete(name = element_blank()) +
  theme(legend.position = c(.15,.3), legend.direction = "vertical",
        legend.title.align = .5,
        legend.title = element_text(size = 8, angle = 90))
```

```{r lag-table,  results="asis", tab.env = "table", cache = T}
lag_model <- glmer(cbind(modality != "gesture", modality== "gesture") ~ 
                          log(freq) * scale(age) + 
                     new_discourse*log(freq) +  new_discourse*scale(age)+
                     (scale(age)|subj) + (1|referent),
                   control = glmerControl(optimizer = "bobyqa"),
                        family = "binomial", 
                   data = filter(lags, person == "child", 
                                 ref_predicted == "1"))

lag_table <- tidy_table(lag_model) %>%
  mutate(term = c("Intercept", "log frequency", "age",
                  "new discourse", "log freq * age",
                  "log freq * new disc",
                  "age * new disc")) %>%
    xtable(caption = "Coefficient estimates for a mixed-effects logistic
           regression predicting probability of prodution in speech for a
           referential event. The model was specified as \\texttt{speech
           $\\sim$ log(freq) * scale(age) +  new\\_discourse * log(freq) +
           new\\_discourse * scale(age) + (scale(age)|subj) + (1|referent)}",
           label = "tab:lag-table")

print(lag_table, type = "latex", comment = F, table.placement = "tb",
      include.rownames = FALSE)
```


```{r, eval = F}
sub_lag_refs <- sub_data %>% 
  ungroup() %>%
  distinct(age, subj, referent) %>%
  unite(identifier, age, subj, referent, sep = "-") %>%
  pull()

sub_lag_data <- lags %>%
  unite(identifier, age, subj, referent, sep = "-") %>%
  filter(identifier %in% sub_lag_refs) %>%
  separate(identifier, c("age", "subj", "referent"), sep = "-") %>%
  mutate(age = as.numeric(age))

sub_lag_model <- glmer(cbind(modality != "gesture", modality== "gesture") ~ 
                          log(freq) * scale(age) + new_discourse +
                     (scale(age)|subj) + (1|referent),
                       family = "binomial",
                   data = filter(sub_lag_data, person == "child", 
                                 ref_predicted == "1"))
```

# Discussion

Even before they can produce, or even maybe know, the words for many objects in the world around them, infants use deictic gestures like pointing to share attention to objects in the world with their caregivers [@bruner1983;@tomasello2007]. As infants develop, they will gradually point less and speak more, communicating with their newly acquired words instead. However, their ability to retrieve these may still be fragile, lagging behind their desire to communicate about them. Our analyses analyses show that that children return to gesture in exactly these conditions: When retrieving a word would take too long. We take this as evidence that infants are tuned to the time pressure of communication, and that their production systems reflect this tuning.

When children are older, they are notorious for asking endless questions. In her analyses of naturalistic recordings of 2--5-year-old children, @chouinard2007 reports that these children ask over 100 questions per hour of interaction with adults. These questions are powerful, allowing children to simultaneously learn about the world and about the language people use to explain it. By driving the discourse into predictable areas of content, they can reduce referential ambiguity in learning new language for this content.

Long before they can explicitly direct their input with wh-questions, children can sometimes achieve a similar outcome simply by referring to objects in their environment. Having observed a referential event, parents will often follow-in with expansions and additional information about the child's target of interest [@goldin-meadow2007]. Our findings add to a growing body of literature suggesting that infants are not merely passive recipients of linguistic input, but active participants in the conversations from which they learn language [@bruner1983; @tamis-lemonda2014].

\vspace{1em} \fbox{\parbox[b][][c]{7.3cm}{\centering All code for these analyses are available at\ \url{https://github.com/dyurovsky/gesture}}}


# Acknowledgements

This research was funded by a James S. McDonnell Foundation Scholar Award to DY and NIH P01HD40605 to SGM.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}

\noindent
